#include <assert.h>
#include <cuda_runtime.h>
#include <stdio.h>

#include <cmath>
#include <iostream>
#include <fstream>
#include "helper.h"

#define CUDA_CHECK(condition)                                          \
  do {                                                                 \
    cudaError_t error = condition;                                     \
    if (error != cudaSuccess) {                                        \
      printf("CUDA_CHECK error in line %d of file %s: %s\n", __LINE__, \
             __FILE__, cudaGetErrorString(cudaGetLastError()));        \
      exit(EXIT_FAILURE);                                              \
    }                                                                  \
  } while (0)
#ifdef DEBUG
#define DEBUG_BLOCK(expr) \
  do {                    \
    expr                  \
  } while (0)
#else
#define DEBUG_BLOCK(...) \
  do {                   \
  } while (0)
#endif
bool read_bin(const char*filename, float *h_data,size_t num_elements){
    std::ifstream file(filename,std::ios::binary);
    if(!file){
        printf(" failed to open file %s\n",filename);
        return false;
    }
    file.read((char*)h_data,num_elements*sizeof(float));
    if(!file){
        printf(" failed to read file %s\n",filename);
        file.close();
        return false;
    }
    file.close();
    printf("loaded %s  (%zu elements)",filename,num_elements);
    return true;
}

__global__ void naive_nrow_gemm(float *A, float *B, float *C, float a, float b,
                                int M , int N,int K ,int mBlock){
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    idx *= mBlock; //è¿™é‡Œä¹˜mBlockçš„ä½œç”¨æ˜¯å°†çº¿ç¨‹å·æ˜ å°„æˆèµ·å§‹è¡Œå·ã€‚æ¯”å¦‚0å·çº¿ç¨‹è´Ÿè´£ä»0è¡Œå¼€å§‹ï¼Œ1å·çº¿ç¨‹ï¼Œè´Ÿè´£ä»mBlockè¡Œå¼€å§‹ï¼Œ2å·çº¿ç¨‹ä»2*mBlockå¼€å§‹
    for (int i = idx; i < idx + mBlock; i++) {
        //ä¸å¯¹å•Š è¿™ä¸ªidx+ mBlockå¯¹å—ï¼Ÿ  è¿™é‡Œæ˜¯+2 å•Š
        //è¿™é‡Œå¾ˆç®€å• å•çº¯çš„çŸ©é˜µç›¸ä¹˜  å¯¹äºAä¸­çš„ä¸€è¡Œï¼Œ éå†Bä¸­çš„æ¯ä¸€åˆ— ï¼ˆéå†æ¯ä¸€åˆ—ä¸­çš„æ¯ä¸€ä¸ªå…ƒç´ ï¼‰
        for(int j=0 ; j<N; j++){
            float sum = 0.f;
            for(int k=0; k<K; k++){
                //ä½ è¿˜åˆ«è¯´ è¿™é‡Œçš„Bå¯èƒ½æ²¡æœ‰è½¬ç½®
                sum += A[i*K+k]*B[j*K+k];
            }
            C[i*N+j] = a*sum + b*C[i*N+j];
        }
    }
}

__global__ void row_softmax(float *input, float *output, int n) {
    //softmax = (e^{x_i}-e^{x_max})/(sum(  e^{x_i}-e^{x_max}   ))
    int idx = threadIdx.x + blockDim.x * blockIdx.x;
    float max_val = -INFINITY;
    float sum = 0.f;
    //è¿™é‡Œå°±æ˜¯æ‰¾åˆ°æ¯ä¸€è¡Œçš„æœ€å¤§å€¼
    for (int i = 0; i < n; i++) {
        if (input[idx * n + i] > max_val) {
            max_val = input[idx * n + i];
        }
    }
    //ä¸Šè¾¹æ˜¯æ‰¾åˆ°æœ€å¤§å€¼äº†
    for(int i = 0; i < n; i++) {
        //æ­¤å¤„æ±‚ e^{x_i}-e^{x_max}
        output[idx*n+i] = expf(input[idx * n + i] - max_val);
        sum += output[idx*n+i];
    }
    //æ¯ä¸ªä½ç½®å†é™¤ä»¥æ€»å’Œ
    for(int i =0 ; i<n ;i++){
        output[idx*n+i] /= sum;
    }

}

__global__ void naive_pv(float *P, float *V, float *O, int M, int N,int mBlock) {
    int idx = threadIdx.x + blockDim.x * blockIdx.x;
    idx *= mBlock; //åŒæ ·çš„ æ¯ä¸ªidxè´Ÿè´£mBlockè¡Œ è¿™æ ·èµ·å§‹åœ°å€å°±å˜ä¸ºäº†idx
    int K = M;
    //è¿™ä¸ªå†™æ³•è·Ÿ naive_nrow_gemm ä¸€æ ·
    for(int i = idx; i < idx + mBlock; i++) {
        for (int j = 0; j < N; j++) {
            float sum = 0.f;
            for (int k = 0; k < K; k++) {
                sum += P[i * K + k] * V[k * N + j];

            }
            O[i * N + j] = sum;
        }
    }



}


bool write_bin(const char* filename, const float *h_data, size_t num_elements){
    std::ofstream file(filename,std::ios::binary);
    if(!file){
        printf("failed to create file %s\n",filename);
        return false;
    }
    file.write((const char*)h_data,num_elements*sizeof(float));
    file.close();
    printf("saved %s (%zu elements)\n",filename,num_elements);
    return true;
}

void self_attention_cuda(float*Q,float*K ,float *V,float *O, int m, int n){
    int mBlock =2;
    assert(m % mBlock == 0 && "mBlock should align") ;
    float sm_scale = 1.f / sqrtf(static_cast<float>(n));
    float *sm_o ;
    cudaMalloc((void **)&sm_o, m * m * sizeof(float));


    dim3 qk_block(m / mBlock, 1,1);
    naive_nrow_gemm<<<1,qk_block>>>(Q, K, sm_o, sm_scale, 0,m,m, n, mBlock); //è¿™é‡Œåº”è¯¥æ˜¯å¯¹Qå’ŒKè¿›è¡ŒçŸ©é˜µä¹˜æ³•ï¼Œå¾—åˆ°QKçŸ©é˜µ
    cudaDeviceSynchronize();
    DEBUG_BLOCK(CUDA_CHECK(cudaGetLastError()); printf("== naive QK ==\n");print_device_matrix(sm_o, m, m););

    //è·å¾—äº†QK[m,m]
    dim3 sm_block(m, 1,1); //è¿™é‡Œå°±æ˜¯ mä¸ªçº¿ç¨‹è´Ÿè´£softmaxå½’ä¸€åŒ–
    row_softmax<<<1, sm_block>>>(sm_o, sm_o, m);
    cudaDeviceSynchronize();
    DEBUG_BLOCK(CUDA_CHECK(cudaGetLastError()); printf("==naive softmax QK ==\n");print_device_matrix(sm_o, m, m););


    //è®¡ç®— QK[m,m] V[m,n]
    dim3 qkv_block(m / mBlock, 1,1);
    naive_pv<<<1,qkv_block>>>(sm_o,V,O,m,n ,mBlock);
    cudaDeviceSynchronize();
    CUDA_CHECK(cudaGetLastError();printf("===== naive softmax(QK)V ==\n");print_device_matrix(O, m, n););



    cudaFree(sm_o);
}

void self_attention_with_io(int m, int n){
    size_t num_elements = m*n;

    //CPUå†…å­˜åˆ†é…
    float *h_Q = new float[num_elements];
    float *h_K = new float[num_elements];
    float *h_V = new float[num_elements];
    float *h_O = new float[num_elements];

    read_bin("/cuda_code/course9/tmp/Q.bin",h_Q, num_elements);
    read_bin("/cuda_code/course9/tmp/K.bin",h_K, num_elements);
    read_bin("/cuda_code/course9/tmp/V.bin",h_V, num_elements);

    //GPUå†…å­˜åˆ†é…
    float *d_Q, *d_K ,*d_V, *d_O;
    cudaMalloc(&d_Q, num_elements*sizeof(float));
    cudaMalloc(&d_K, num_elements*sizeof(float));
    cudaMalloc(&d_V, num_elements*sizeof(float));
    cudaMalloc(&d_O, num_elements*sizeof(float));

    //æŠŠæ•°æ®æŒªåˆ°GPUä¸Š
    cudaMemcpy(d_Q, h_Q, num_elements*sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_K, h_K, num_elements*sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_V, h_V, num_elements*sizeof(float), cudaMemcpyHostToDevice);

    // run self-attention
    self_attention_cuda(d_Q,d_K, d_V, d_O, m, n);

    //æŠŠç»“æœæ‹·è´å›CPU
    cudaMemcpy(h_O, d_O, num_elements*sizeof(float), cudaMemcpyDeviceToHost);

    write_bin("/cuda_code/course9/tmp/O_cuda.bin", h_O, num_elements);

    delete[] h_Q;
    delete[] h_K;
    delete[] h_V;
    delete[] h_O;
    cudaFree(d_Q);
    cudaFree(d_K);
    cudaFree(d_V);
    cudaFree(d_O);
    printf("ğŸ‰ Self-attention completed. Output saved to O_cuda.bin\n");

}













int main(){
    const int m = 64;
    const int n =128;

    printf("Running self-attention for m=%d, n=%d\n", m, n);
    self_attention_with_io(m,n);

    return 0;
}